{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# From Keras to tf.keras and tf to tf 2.0: The Journey\n",
    "\n",
    "Keras could be seen as a what we call the `Wrapper` of either `tensorflow`, `theano` or `CNTK` before the release of `tensorflow 2.0` but it's definition has changed since the rlease of `tf 2.0`. Keras was not in active development for quite some time and was not compatible with `python > 3.5` but a week ago or so, they have released a new version which is now compatible with `python >= 3.6`. \n",
    "\n",
    "# The Change:\n",
    "\n",
    "`Tensorflow 2.0` is IMO, a complete shift as a lots of things have changed. I'd say that it has been for better specially for those who wanted to be somewhere between high level Keras for faster developments and  tensorflow for research and very high customization as `tf 2.0` provides both. So it won't be completly wrong to say that tf 2.0 and Keras are almost same today. We'll be looking at the aspect of building a custom Model and Layer using the tf 2.0 and Keras.\n",
    "\n",
    "Aprt from that tensorflow has allowed the **Eager Execution** where you can see the results right away instad of building a static graph so that was an exclusiveness `PyTorch` **USED** to have. So it has become Build **and** run (how python works) instead of build **then** run (how c/c++ works)."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Layers\n",
    "Before we start, we need to note some important facts about layers:\n",
    "\n",
    "1. Each layer uses the `tf.keras.layers.Layer` as a parent class.\n",
    "\n",
    "2. There are weights associated with layers. These weights can be trainable or non-trainable according to your requirement.\n",
    "\n",
    "3. Every layer is initialized with initial weights and it can be any of the `tf.keras.initializers` such as `zeros`, `normal`, `ones` and the most widely used `glorot_uniform`.\n",
    "\n",
    "4. Layers can be recursively combined (inside one another). So the outer layer will depend on the weights of the inner layer.\n",
    "\n",
    "5. We need to have the understanding of the shape of Input coming to the layer and number of output neurons it'll give as an output. We usually do no know the shape so we use a method `build` to get the shape while forward pass.\n",
    "\n",
    "6. A layer may or not have the `loss function` or the `Regularization`. If there are any transformations  implemented in the layers, these have to be executed inside the `call`  (for forward pass) method.\n",
    "\n",
    "7. There are few methods that we can choose to apply. `__init__`  and `call` is a must and using the `build` method before initializing the weights is the best practice to follow in dynamic environments. `grt_config` and `from_config` are used if we want to serialize our layers (for saving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.activations import relu,sigmoid, softmax, tanh\n",
    "from tensorflow.keras.initializers import glorot_normal\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDense(Layer):\n",
    "    '''\n",
    "    Build custom layer mimicks the Dense Layer\n",
    "    '''\n",
    "    def __init__(self,units=128,initializer='glorot_uniform',activation=None,name=None,**kwargs):\n",
    "        '''\n",
    "        Constructor of the class\n",
    "        args:\n",
    "            units: {int} number of neurons in the layer\n",
    "            initializer: {string or callable instance of tf.keras.initializers } initial weights\n",
    "            activation: {callable instance of tf.keras.activations} activation function to use\n",
    "            name: name of the layer {string}. There is already a name param in Base Class\n",
    "            kwargs: keyword arguments of the base Layer Class\n",
    "        '''\n",
    "        super(CustomDense,self).__init__(**kwargs) # constructor of Base Layer class\n",
    "        self.units = units # number of neurons\n",
    "        self.activation = activation # activation function\n",
    "        self.initializer = initializer # initializer\n",
    "        if name: # it works but but you SHOUD NOT USE IT\n",
    "            self._name = name\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        '''\n",
    "        method typically used to create the weights of Layer subclasses. During forward pass or call() model\n",
    "        will automatically call the build method to get the shape of the input tensor\n",
    "        args:\n",
    "            input_shape: a tensor describing shape of input. it'll be passed automatically as input.shape\n",
    "        '''\n",
    "        self.w = self.add_weight(shape=(input_shape[-1],self.units),initializer=self.initializer,trainable=True)\n",
    "        # add_weight is a method of Layer base class. input_shape[-1] gives number of features\n",
    "        \n",
    "        self.b = self.add_weight(shape=(self.units,),initializer=self.initializer,trainable=True)\n",
    "        # add bias and set to trainable. NOTE: never forget to add a , after self.units as\n",
    "        # (1) == int(1) but (1,) = tuple([1])\n",
    "\n",
    "        \n",
    "    def call(self,input_tensor):\n",
    "        '''\n",
    "        method to implement the forward pass\n",
    "        args:\n",
    "            input: input tensor\n",
    "        '''\n",
    "        result = tf.matmul(input_tensor,self.w)+self.b \n",
    "        # apply the formula y = wx + b in matric multiplication form\n",
    "        \n",
    "        if self.activation:\n",
    "            result = self.activation(result) # apply activation function\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[-0.02950236, -0.00495137, -0.00252123],\n",
       "       [ 0.01312666, -0.02502874, -0.02675922],\n",
       "       [-0.03385033, -0.00761297, -0.02917661],\n",
       "       [ 0.03630997,  0.02617916,  0.03764183]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CustomDense(8,activation=softmax,name='my_layer')\n",
    "\n",
    "# below code is to just create random tensor which will work as the input to the Layer\n",
    "ini = tf.random_uniform_initializer()\n",
    "tensor = ini((4,3)) # 4 data points with 3 attributes\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8), dtype=float32, numpy=\n",
       "array([[0.18900216, 0.12751332, 0.11943944, 0.20081049, 0.08404858,\n",
       "        0.0863165 , 0.09276157, 0.10010795],\n",
       "       [0.19242592, 0.12541182, 0.12281655, 0.19617727, 0.08546472,\n",
       "        0.08314477, 0.09559486, 0.09896398],\n",
       "       [0.18809876, 0.12761146, 0.11893441, 0.20296454, 0.08299486,\n",
       "        0.08540022, 0.0938602 , 0.10013554],\n",
       "       [0.19753608, 0.12389737, 0.12073223, 0.1900218 , 0.08861208,\n",
       "        0.08450832, 0.0930167 , 0.10167544]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(layer(tensor)[0].numpy().sum())  \n",
    "# to check if our model is outputting correct sigmoid as sum==1 for each row\n",
    "layer(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'my_layer/Variable:0' shape=(3, 8) dtype=float32, numpy=\n",
       " array([[ 0.56216127, -0.39661252,  0.42390555, -0.669488  ,  0.6075563 ,\n",
       "         -0.592629  ,  0.4019621 ,  0.00183886],\n",
       "        [ 0.20696324, -0.07819968, -0.69159585,  0.09262097, -0.00578594,\n",
       "         -0.00544608, -0.0497759 ,  0.6573182 ],\n",
       "        [ 0.17576718,  0.15202194,  0.267255  , -0.19194454,  0.48316234,\n",
       "          0.6059707 , -0.39392868,  0.03210783]], dtype=float32)>,\n",
       " <tf.Variable 'my_layer/Variable:0' shape=(8,) dtype=float32, numpy=\n",
       " array([ 0.3222744 , -0.10102111, -0.14497197,  0.34504777, -0.4870283 ,\n",
       "        -0.4954994 , -0.3968854 , -0.32789817], dtype=float32)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weights # weights and biases. we can access layer.b, layer.w individually too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_layer'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.name  # layer._name works too. Not a Private variable as there are no private variables in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Privilaged argument in the `Call()`\n",
    "There is a special argument  `training`  given for the call method. You can use the Boolean {True, False} for this option to use in Custom Layer to tell if the layer is working with Training or inference (results). For example, there are some methods where you can train differently and when you have to predict, a different strategy is used. For example you can dropout in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HypotheticalLayer(Layer):\n",
    "    '''\n",
    "    Build a random layer\n",
    "    '''\n",
    "    def __init__(self,units=4,initializer='glorot_uniform',drop_rate=0.23,**kwargs):\n",
    "        super(HypotheticalLayer,self).__init__(**kwargs) # constructor of Base Layer class\n",
    "        self.units = units # number of neurons\n",
    "        self.initializer = initializer # initializer\n",
    "        self.drop_rate = drop_rate\n",
    "        \n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        self.w = self.add_weight(shape=(input_shape[-1],self.units),initializer=self.initializer,trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight(shape=(self.units,),initializer=self.initializer,trainable=True)\n",
    "   \n",
    "        \n",
    "    def call(self,input_tensor,training=False):\n",
    "        '''\n",
    "        method to implement the forward pass with training parm\n",
    "        args:\n",
    "            input: input tensor\n",
    "            training: {bool} whether the layer is in training phase or not\n",
    "        '''\n",
    "        result = tf.matmul(input_tensor,self.w)+self.b \n",
    "        \n",
    "        if training:\n",
    "            result = tf.nn.dropout(result,rate=self.drop_rate) # apply dropout\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.5403205 ,  1.2124445 , -0.0805456 ,  0.8686729 ],\n",
       "       [ 0.58374757,  1.1929944 , -0.02930541,  0.90038687],\n",
       "       [ 0.558274  ,  0.        , -0.        ,  0.        ],\n",
       "       [ 0.        ,  1.2389462 , -0.06333673,  0.        ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo_layer = HypotheticalLayer(drop_rate=0.33)\n",
    "hypo_layer(tensor,training=True) # uses the call method. Apply dropout randomly to 33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.36201477,  0.8123379 , -0.05396555,  0.58201087],\n",
       "       [ 0.39111087,  0.7993062 , -0.01963463,  0.6032592 ],\n",
       "       [ 0.37404358,  0.805547  , -0.04686815,  0.5788237 ],\n",
       "       [ 0.36929113,  0.830094  , -0.04243561,  0.5756116 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypo_layer(tensor) # default training=False"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Nested Layers\n",
    "We'll try to build a layer composed of multiple `CustomDense` layers with activation associated with each. \n",
    "Just for the demonstration purpose, we'll cover multiple scenario of how can we initialise our `CustomLayer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedDense(Layer):\n",
    "    '''\n",
    "    Build nested layer made of multiple CustomDense layer\n",
    "    '''\n",
    "    def __init__(self,l1_unit=8,l2_unit=8,l2_units=4,**kwargs):\n",
    "        '''\n",
    "        Constructor of the class\n",
    "        args:\n",
    "            l1_units, l2_units, l3_units = no of neurons in the 3 sub layers\n",
    "            kwargs: keyword arguments of the base Layer Class\n",
    "        '''\n",
    "        super(NestedDense,self).__init__(**kwargs) # constructor of Base Layer class\n",
    "        \n",
    "        self.l1 = CustomDense(l1_unit,initializer=glorot_normal) # no activation, callable initializer\n",
    "        self.l2 = CustomDense(l2_units,initializer='ones',activation=relu) \n",
    "        # relu activation, he_uniform initializer\n",
    "        self.l3 = CustomDense(l1_unit) # no activation. default initializer\n",
    "\n",
    "        \n",
    "    def call(self,input_tensor):\n",
    "        '''\n",
    "        method to implement the forward pass\n",
    "        args:\n",
    "            input: input tensor\n",
    "        '''\n",
    "        x = self.l1(input_tensor) # layer 1 \n",
    "        x = tanh(x) # as we had no activation function in layer 1\n",
    "        \n",
    "        x = self.l2(x) # pass to layer 2. we have a default activation as relu\n",
    "        \n",
    "        x = self.l3(x) # for our hypothetical work, we do not need any activation for output\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8), dtype=float32, numpy=\n",
       "array([[ 2.5076945e+00, -7.9610229e-01,  8.6938989e-01,  1.4206990e+00,\n",
       "        -2.1850250e+00,  1.9344091e-03,  1.9144945e+00, -1.1088862e+00],\n",
       "       [ 2.6646819e+00, -8.2978290e-01,  9.2027736e-01,  1.5047566e+00,\n",
       "        -2.3183215e+00, -1.7661750e-02,  2.0594294e+00, -1.1892037e+00],\n",
       "       [ 2.5011158e+00, -7.9469085e-01,  8.6725748e-01,  1.4171766e+00,\n",
       "        -2.1794391e+00,  2.7555823e-03,  1.9084210e+00, -1.1055205e+00],\n",
       "       [ 2.6480989e+00, -8.2622510e-01,  9.1490197e-01,  1.4958774e+00,\n",
       "        -2.3042409e+00, -1.5591741e-02,  2.0441196e+00, -1.1807194e+00]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_dense = NestedDense()\n",
    "nested_dense(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'nested_dense/custom_dense_1/Variable:0' shape=(3, 8) dtype=float32, numpy=\n",
       " array([[ 0.21393721,  0.70684   ,  0.6212779 ,  0.20657147,  0.2349035 ,\n",
       "          0.4939701 ,  0.59531415, -0.95688975],\n",
       "        [ 0.02069471,  0.11810245, -0.5300749 , -0.4921239 , -0.3508117 ,\n",
       "         -0.03057094, -0.40324438,  0.5845389 ],\n",
       "        [ 0.8529533 , -0.25923324,  0.7479166 , -0.06946068, -0.942283  ,\n",
       "          0.05722449, -0.23094518,  0.06954481]], dtype=float32)>,\n",
       " <tf.Variable 'nested_dense/custom_dense_1/Variable:0' shape=(8,) dtype=float32, numpy=\n",
       " array([ 0.5866819 ,  0.07573399,  0.49254066, -0.26131037,  0.27363467,\n",
       "         0.05302572,  0.26541996, -0.49118564], dtype=float32)>,\n",
       " <tf.Variable 'nested_dense/custom_dense_2/Variable:0' shape=(8, 4) dtype=float32, numpy=\n",
       " array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], dtype=float32)>,\n",
       " <tf.Variable 'nested_dense/custom_dense_2/Variable:0' shape=(4,) dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'nested_dense/custom_dense_3/Variable:0' shape=(4, 8) dtype=float32, numpy=\n",
       " array([[ 0.14264703,  0.15721583,  0.41833442,  0.25315893, -0.651726  ,\n",
       "          0.00786597,  0.64072376, -0.34341758],\n",
       "        [ 0.2508579 , -0.5609356 , -0.24748746,  0.66126364, -0.18609536,\n",
       "          0.5041961 ,  0.6661354 , -0.5448048 ],\n",
       "        [ 0.36888856, -0.35836387,  0.27428615,  0.5168143 , -0.3482884 ,\n",
       "         -0.57465476, -0.04098225, -0.2792008 ],\n",
       "        [ 0.66813725,  0.4551726 ,  0.01857311, -0.66527146, -0.02853948,\n",
       "         -0.11597466,  0.05482495,  0.43553776]], dtype=float32)>,\n",
       " <tf.Variable 'nested_dense/custom_dense_3/Variable:0' shape=(8,) dtype=float32, numpy=\n",
       " array([-0.17137375, -0.22132564,  0.00097048, -0.01378512,  0.08974475,\n",
       "         0.33635163, -0.5588884 ,  0.26177377], dtype=float32)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_dense.weights # layer has weights of all the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Serialising Layers\n",
    "When we want to save the layer and use later, we need to use the `get_config()` from the **Parent** or Super Class. `get_config()` needs some configuration such as number of units or other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SerializableLayer(Layer):\n",
    "    '''\n",
    "    Build custom layer mimicks the Dense Layer which can noe be serialised or saved\n",
    "    '''\n",
    "    def __init__(self,units=128,initializer='glorot_uniform',activation=None,**kwargs):\n",
    "        super(SerializableLayer,self).__init__(**kwargs) \n",
    "        self.units = units\n",
    "        self.activation = activation \n",
    "        self.initializer = initializer \n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        self.w = self.add_weight(shape=(input_shape[-1],self.units),initializer=self.initializer,trainable=True)\n",
    "       \n",
    "        self.b = self.add_weight(shape=(self.units,),initializer=self.initializer,trainable=True)\n",
    "        \n",
    "\n",
    "        \n",
    "    def call(self,input_tensor):\n",
    "        '''\n",
    "        method to implement the forward pass\n",
    "        args:\n",
    "            input: input tensor\n",
    "        '''\n",
    "        result = tf.matmul(input_tensor,self.w)+self.b \n",
    "        \n",
    "        if self.activation:\n",
    "            result = self.activation(result)\n",
    "        \n",
    "        return result\n",
    "            \n",
    "            \n",
    "    def get_config(self):\n",
    "        '''\n",
    "        Get the configuration of the layer so that you can serialise the layer for further use\n",
    "        '''\n",
    "        config = super(SerializableLayer,self).get_config() # get the configuration from the Base Layer\n",
    "        config.update({'units':self.units,'initializer':self.initializer})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_l_default\n",
      "{'name': 's_l_default', 'trainable': True, 'dtype': 'float32', 'units': 12, 'initializer': 'glorot_uniform'}\n"
     ]
    }
   ],
   "source": [
    "layer = SerializableLayer(units=12,**{'name':'s_l_default'}) \n",
    "# see the working of name. this 'name' parameter is from the base Layer class.\n",
    "print(layer.name)\n",
    "config = layer.get_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 's_l_default',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'units': 12,\n",
       " 'initializer': 'glorot_uniform'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_layer = SerializableLayer.from_config(config) # make an exact copy of the above layer\n",
    "new_layer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Custom Models\n",
    "In general, we will use the `Layer` class to define inner computation blocks, and will use the `Model` class to define the outer **model -- the object we will train.**\n",
    "\n",
    "For instance, in a `ResNet50` model, we have **several ResNet blocks subclassing Layer, and a single Model encompassing the entire ResNet50 network.**\n",
    "\n",
    "The Model class has the same API as Layer, with the following differences:\n",
    "\n",
    "1. It exposes built-in training, evaluation, and prediction loops (`model.fit()`, `model.evaluate()`, `model.predict()`).\n",
    "2. It exposes the list of its inner layers, via the `model.layers` property.\n",
    "3. It exposes saving and serialization APIs (`save()`, `save_weights()`...)\n",
    "\n",
    "-[from tf documentation](https://www.tensorflow.org/guide/keras/custom_layers_and_models#the_model_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(Model):\n",
    "    '''\n",
    "    A model that performs simple classification where each input can belong to Only 1 class\n",
    "    '''\n",
    "    def __init__(self,input_shape,num_dense_layers=1,units=8,classes=2,activation='relu',**kwargs):\n",
    "        '''\n",
    "        Constructor of the class to get initial arguments\n",
    "        args:\n",
    "            input_shape = {tuple} shape of incoming data\n",
    "            num_dense_layers: {int} number of dense layers to include in the classification\n",
    "            units: {int} units to use for each layer\n",
    "            classes: {int} Number of classes either binary or multiclass\n",
    "            activation = {string/callable} activation function to use\n",
    "        '''\n",
    "        super(ClassificationModel,self).__init__(**kwargs)\n",
    "        \n",
    "        assert num_dense_layers>=1 , \"number of layers must be >=1\"\n",
    "        assert units>=1 , \"units must be >=1\"\n",
    "        assert classes>=2, \"classes must be >=2\"\n",
    "        \n",
    "        self.in_shape = input_shape\n",
    "        self.n_dense = num_dense_layers\n",
    "        self.units = units\n",
    "        self.classes = classes\n",
    "        self.activation = activation\n",
    "        \n",
    "        \n",
    "        self.in_layer = tf.keras.layers.Dense(self.units,input_shape=self.in_shape,\n",
    "                                          activation=self.activation,kernel_initializer='glorot_uniform',)\n",
    "        # input layer has Input_shape param\n",
    "        \n",
    "        \n",
    "        self.middle_layers = [] # middle layers do not have Input_shape\n",
    "        for i in range(1,self.n_dense-1):\n",
    "            self.middle_layers.append(tf.keras.layers.Dense(self.units,activation=self.activation,\n",
    "                                                     kernel_initializer='glorot_uniform',))\n",
    "            \n",
    "        if self.classes == 2:\n",
    "            self.out_layer = tf.keras.layers.Dense(1,activation='sigmoid',\n",
    "                                                   kernel_initializer='glorot_uniform',)\n",
    "        else:\n",
    "            self.out_layer = tf.keras.layers.Dense(self.classes,activation='softmax',\n",
    "                                            kernel_initializer='glorot_uniform')\n",
    "            \n",
    "        \n",
    "    def call(self,tensor):\n",
    "        '''\n",
    "        Perform a forward pass operation\n",
    "        '''\n",
    "        x = self.in_layer(tensor)\n",
    "\n",
    "        for layer in self.middle_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        probs = self.out_layer(x)\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7f8f0c518510>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f8ef477e450>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f8ef477e1d0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassificationModel(tensor.shape,3,8,2) # 3 layers with 8 units each and binary classification\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  9         \n",
      "=================================================================\n",
      "Total params: 113\n",
      "Trainable params: 113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.summary() won't work without a fit() or build() method. we can pass in a tensor as a workaround\n",
    "probs = model(tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Custom Model with Custom Layers\n",
    "Now, We'll build a Custom Model with custom Layers in it. We'll add a few given layers such as Dropout too to get an understanding that we can mix and match the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(Layer):\n",
    "    '''\n",
    "    Fully Connected or Dense layer \n",
    "    '''\n",
    "    def __init__(self,units=16,w_init='he_uniform',b_init='zeros',activation=None,**kwargs):\n",
    "        '''\n",
    "        Constructor of the class\n",
    "        args:\n",
    "            units: {int} number of neurons to use\n",
    "            w_init = {string/callable} weight initializer\n",
    "            b_init = {string/callable/None} bias initializer. None if no bias is included\n",
    "            activation: {string} activation function to use\n",
    "            **kwargs: {dict} keyword arg for the parent class\n",
    "        '''\n",
    "        super(FullyConnected,self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.w_init = w_init\n",
    "        self.b_init = b_init\n",
    "        self.activation = tf.keras.activations.get(activation) # gives a respective callable. None gives linear\n",
    "        \n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        '''\n",
    "        Assign weights to the layer dynamically. Base layer method\n",
    "        '''\n",
    "        self.w = self.add_weight(shape=(input_shape[-1],self.units),initializer=self.w_init,trainable=True)\n",
    "        if self.b_init:\n",
    "            self.b = self.add_weight(shape=(self.units,),initializer=self.b_init,trainable=True)\n",
    "        \n",
    "    \n",
    "    def call(self,input_tensor):\n",
    "        '''\n",
    "        Forward Pass. Part of Base layer\n",
    "        '''\n",
    "        result = tf.matmul(input_tensor,self.w)\n",
    "        if self.b_init:\n",
    "            result = result + self.b\n",
    "            \n",
    "        if self.activation:\n",
    "            result = self.activation(result)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        '''\n",
    "        Method of base class which computes the shape of output. \n",
    "        compute_output_shape is not needed unless the Layer is Dynamic\n",
    "        args:\n",
    "            input_shape: (tuple) shape of incoming tensor\n",
    "        out:\n",
    "            out_shape: (tuple)  shape of resulting tensor\n",
    "        '''\n",
    "        out_shape = list(input_shape) # because we can not append to tuple\n",
    "        out_shape[-1] = self.units # replace the incoming feature dimension to outgoing\n",
    "        return tuple(out_shape) # a tuple is needed for shape\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(FullyConnected,self).get_config() # get config of the base Layer class\n",
    "        \n",
    "        config.update({'units':self.units,'activation':tf.keras.activations.serialize(self.activation)})\n",
    "        # you need to serialise the callable activation function\n",
    "        \n",
    "        return config  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(Model):\n",
    "    '''\n",
    "    A model that performs simple classification where each input can belong to Only 1 class\n",
    "    '''\n",
    "    def __init__(self,input_shape,layers_units=[8,],classes=2,activation='relu',**kwargs):\n",
    "        '''\n",
    "        Constructor of the class to get initial arguments\n",
    "        args:\n",
    "            input_shape = {tuple} shape of incoming data\n",
    "            layer_units: {list} units to use for each layer\n",
    "            classes: {int} Number of classes either binary or multiclass\n",
    "            activation = {string/callable} activation function to use\n",
    "        '''\n",
    "        super(ClassificationModel,self).__init__(**kwargs)\n",
    "        \n",
    "        assert len(layers_units)>=1 , \"units must be >=1\"\n",
    "        assert classes>=2, \"classes must be >=2\"\n",
    "        \n",
    "        self.in_shape = input_shape\n",
    "        self.units = layers_units\n",
    "        self.classes = classes\n",
    "        self.activation = activation\n",
    "        \n",
    "        \n",
    "        self.in_layer = FullyConnected(self.units[0],activation=self.activation,\n",
    "                                       name='input_layer',\n",
    "                                       input_shape=self.in_shape)\n",
    "        # input_shape is a parameter of base class\n",
    "        \n",
    "        \n",
    "        self.middle_layers = [] # middle layers do not have Input_shape\n",
    "        for i in range(1,len(self.units)):\n",
    "            self.middle_layers.append(FullyConnected(self.units[i],activation=self.activation))\n",
    "            \n",
    "            \n",
    "        if self.classes == 2:\n",
    "            self.out_layer = FullyConnected(1,activation='sigmoid',name='output_layer')\n",
    "        else:\n",
    "            self.out_layer = FullyConnected(self.classes,activation='softmax',name='output_layer')\n",
    "            \n",
    "        \n",
    "    def call(self,tensor):\n",
    "        '''\n",
    "        Perform a forward pass operation\n",
    "        '''\n",
    "        x = self.in_layer(tensor)\n",
    "\n",
    "        for layer in self.middle_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        probs = self.out_layer(x)\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training Model\n",
    "You can train the above model with `keras.Dense()` layer or you can add `FullyConnected()` to `keras.Sequential()/keras.Model()` API too to check how is it performing. We'll train our custom model using our custom layer to classify the wine dataset. It is a multi (3) class classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X = wine['data']\n",
    "y = wine['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.FullyConnected at 0x7f8ef477eb90>,\n",
       " <__main__.FullyConnected at 0x7f8ef474ef50>,\n",
       " <__main__.FullyConnected at 0x7f8ef478c810>,\n",
       " <__main__.FullyConnected at 0x7f8ef477b9d0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassificationModel(input_shape=X_train.shape,layers_units=[64,32,32],classes=3,activation='relu')\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# you can also pass all the parameters as callable\n",
    "\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 456.8831 - accuracy: 0.2746 - val_loss: 470.7413 - val_accuracy: 0.2500\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 432.0455 - accuracy: 0.2746 - val_loss: 444.4698 - val_accuracy: 0.2500\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 407.1481 - accuracy: 0.2746 - val_loss: 418.3409 - val_accuracy: 0.2500\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 382.6049 - accuracy: 0.2746 - val_loss: 392.2401 - val_accuracy: 0.2500\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 358.6322 - accuracy: 0.2746 - val_loss: 366.3926 - val_accuracy: 0.2500\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 334.6218 - accuracy: 0.2746 - val_loss: 341.2526 - val_accuracy: 0.2500\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 311.6069 - accuracy: 0.2746 - val_loss: 317.1813 - val_accuracy: 0.2500\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 289.4217 - accuracy: 0.2746 - val_loss: 295.3412 - val_accuracy: 0.2500\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 269.0434 - accuracy: 0.2746 - val_loss: 274.5162 - val_accuracy: 0.2500\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 249.1496 - accuracy: 0.2746 - val_loss: 254.2753 - val_accuracy: 0.2500\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 230.1510 - accuracy: 0.2746 - val_loss: 234.0888 - val_accuracy: 0.2500\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 211.5885 - accuracy: 0.2746 - val_loss: 214.2223 - val_accuracy: 0.2500\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 192.9549 - accuracy: 0.2746 - val_loss: 194.8421 - val_accuracy: 0.2500\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 174.8468 - accuracy: 0.2746 - val_loss: 175.4733 - val_accuracy: 0.2500\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 156.5181 - accuracy: 0.2746 - val_loss: 156.5723 - val_accuracy: 0.2500\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 139.6572 - accuracy: 0.2746 - val_loss: 137.6541 - val_accuracy: 0.2500\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 121.8319 - accuracy: 0.2746 - val_loss: 119.1298 - val_accuracy: 0.2500\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 104.9930 - accuracy: 0.2746 - val_loss: 100.5368 - val_accuracy: 0.2500\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 87.4285 - accuracy: 0.2746 - val_loss: 82.4329 - val_accuracy: 0.2500\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 70.7537 - accuracy: 0.2746 - val_loss: 64.4182 - val_accuracy: 0.2500\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 53.9647 - accuracy: 0.2746 - val_loss: 46.5725 - val_accuracy: 0.2778\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 39.6651 - accuracy: 0.2535 - val_loss: 37.0141 - val_accuracy: 0.2500\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 32.7125 - accuracy: 0.3028 - val_loss: 28.5623 - val_accuracy: 0.4167\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 24.4171 - accuracy: 0.3592 - val_loss: 18.7159 - val_accuracy: 0.3889\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 15.2397 - accuracy: 0.3451 - val_loss: 9.5030 - val_accuracy: 0.4167\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7.7385 - accuracy: 0.3732 - val_loss: 3.6022 - val_accuracy: 0.5278\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.0005 - accuracy: 0.5141 - val_loss: 1.8657 - val_accuracy: 0.6111\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0880 - accuracy: 0.6127 - val_loss: 2.8456 - val_accuracy: 0.6389\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9532 - accuracy: 0.5634 - val_loss: 3.2541 - val_accuracy: 0.6111\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.1133 - accuracy: 0.5563 - val_loss: 2.9728 - val_accuracy: 0.5833\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.7015 - accuracy: 0.5563 - val_loss: 2.4618 - val_accuracy: 0.6389\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2676 - accuracy: 0.5915 - val_loss: 2.0638 - val_accuracy: 0.6111\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.1649 - accuracy: 0.6056 - val_loss: 1.8530 - val_accuracy: 0.5833\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0954 - accuracy: 0.5845 - val_loss: 1.7741 - val_accuracy: 0.6111\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0816 - accuracy: 0.5986 - val_loss: 1.7733 - val_accuracy: 0.6389\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0951 - accuracy: 0.6127 - val_loss: 1.7889 - val_accuracy: 0.6389\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0781 - accuracy: 0.6127 - val_loss: 1.8069 - val_accuracy: 0.6111\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0590 - accuracy: 0.6127 - val_loss: 1.8482 - val_accuracy: 0.6111\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0356 - accuracy: 0.5986 - val_loss: 1.8501 - val_accuracy: 0.6111\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.0343 - accuracy: 0.6056 - val_loss: 1.8709 - val_accuracy: 0.6111\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0340 - accuracy: 0.6056 - val_loss: 1.8915 - val_accuracy: 0.6111\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0344 - accuracy: 0.6056 - val_loss: 1.8897 - val_accuracy: 0.6111\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0252 - accuracy: 0.5986 - val_loss: 1.8695 - val_accuracy: 0.6111\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0271 - accuracy: 0.5986 - val_loss: 1.8644 - val_accuracy: 0.6111\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0214 - accuracy: 0.5986 - val_loss: 1.8552 - val_accuracy: 0.6111\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0145 - accuracy: 0.6197 - val_loss: 1.8528 - val_accuracy: 0.6111\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0117 - accuracy: 0.6056 - val_loss: 1.8301 - val_accuracy: 0.6111\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0063 - accuracy: 0.6056 - val_loss: 1.8215 - val_accuracy: 0.6111\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.0085 - accuracy: 0.6056 - val_loss: 1.8078 - val_accuracy: 0.6111\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.0141 - accuracy: 0.5915 - val_loss: 1.8188 - val_accuracy: 0.6111\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0021 - accuracy: 0.5986 - val_loss: 1.8121 - val_accuracy: 0.6111\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0089 - accuracy: 0.5986 - val_loss: 1.7784 - val_accuracy: 0.6111\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9855 - accuracy: 0.5915 - val_loss: 1.7760 - val_accuracy: 0.6111\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9942 - accuracy: 0.5986 - val_loss: 1.7828 - val_accuracy: 0.6111\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9928 - accuracy: 0.6056 - val_loss: 1.8195 - val_accuracy: 0.6111\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9839 - accuracy: 0.5915 - val_loss: 1.8420 - val_accuracy: 0.6111\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9888 - accuracy: 0.6056 - val_loss: 1.7845 - val_accuracy: 0.6111\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9896 - accuracy: 0.6056 - val_loss: 1.7522 - val_accuracy: 0.6111\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.9821 - accuracy: 0.6056 - val_loss: 1.7614 - val_accuracy: 0.6111\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9720 - accuracy: 0.5986 - val_loss: 1.7523 - val_accuracy: 0.6111\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9493 - accuracy: 0.5915 - val_loss: 1.7647 - val_accuracy: 0.6111\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9564 - accuracy: 0.5986 - val_loss: 1.7665 - val_accuracy: 0.6111\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9496 - accuracy: 0.5986 - val_loss: 1.7685 - val_accuracy: 0.6111\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9424 - accuracy: 0.6056 - val_loss: 1.7990 - val_accuracy: 0.6111\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9534 - accuracy: 0.6056 - val_loss: 1.7935 - val_accuracy: 0.6389\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9381 - accuracy: 0.5986 - val_loss: 1.7481 - val_accuracy: 0.6111\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9229 - accuracy: 0.6056 - val_loss: 1.7435 - val_accuracy: 0.6111\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.9267 - accuracy: 0.6197 - val_loss: 1.7350 - val_accuracy: 0.6111\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.9127 - accuracy: 0.6197 - val_loss: 1.7594 - val_accuracy: 0.6111\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9146 - accuracy: 0.6056 - val_loss: 1.7658 - val_accuracy: 0.6111\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9066 - accuracy: 0.5986 - val_loss: 1.7167 - val_accuracy: 0.6111\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.8963 - accuracy: 0.6197 - val_loss: 1.6699 - val_accuracy: 0.6111\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.9043 - accuracy: 0.6197 - val_loss: 1.6542 - val_accuracy: 0.6389\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.8859 - accuracy: 0.5986 - val_loss: 1.6586 - val_accuracy: 0.6111\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8783 - accuracy: 0.6127 - val_loss: 1.6431 - val_accuracy: 0.6111\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.8620 - accuracy: 0.6338 - val_loss: 1.6063 - val_accuracy: 0.6389\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.8621 - accuracy: 0.6338 - val_loss: 1.5966 - val_accuracy: 0.6111\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.8512 - accuracy: 0.6408 - val_loss: 1.6046 - val_accuracy: 0.6111\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8323 - accuracy: 0.6197 - val_loss: 1.6339 - val_accuracy: 0.6111\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8380 - accuracy: 0.6268 - val_loss: 1.6495 - val_accuracy: 0.6389\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.8069 - accuracy: 0.6197 - val_loss: 1.6289 - val_accuracy: 0.6389\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8037 - accuracy: 0.6268 - val_loss: 1.6200 - val_accuracy: 0.6389\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8075 - accuracy: 0.6197 - val_loss: 1.6300 - val_accuracy: 0.6111\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7955 - accuracy: 0.6268 - val_loss: 1.6091 - val_accuracy: 0.6111\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7837 - accuracy: 0.6408 - val_loss: 1.5691 - val_accuracy: 0.6111\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7819 - accuracy: 0.6479 - val_loss: 1.5454 - val_accuracy: 0.6111\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.7917 - accuracy: 0.6268 - val_loss: 1.5601 - val_accuracy: 0.6111\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7816 - accuracy: 0.6408 - val_loss: 1.5669 - val_accuracy: 0.6111\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7522 - accuracy: 0.6268 - val_loss: 1.5985 - val_accuracy: 0.6111\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7730 - accuracy: 0.6127 - val_loss: 1.6264 - val_accuracy: 0.6389\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7627 - accuracy: 0.6197 - val_loss: 1.6660 - val_accuracy: 0.6667\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7609 - accuracy: 0.6408 - val_loss: 1.6760 - val_accuracy: 0.6667\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7462 - accuracy: 0.6127 - val_loss: 1.6436 - val_accuracy: 0.6111\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7473 - accuracy: 0.6268 - val_loss: 1.6061 - val_accuracy: 0.6111\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7492 - accuracy: 0.6197 - val_loss: 1.6305 - val_accuracy: 0.6111\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7522 - accuracy: 0.6338 - val_loss: 1.6517 - val_accuracy: 0.6389\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.7353 - accuracy: 0.6127 - val_loss: 1.6400 - val_accuracy: 0.6111\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7249 - accuracy: 0.6268 - val_loss: 1.6265 - val_accuracy: 0.6389\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7085 - accuracy: 0.6197 - val_loss: 1.5775 - val_accuracy: 0.6111\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7179 - accuracy: 0.6408 - val_loss: 1.5350 - val_accuracy: 0.6389\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7242 - accuracy: 0.6408 - val_loss: 1.5455 - val_accuracy: 0.6111\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7219 - accuracy: 0.6197 - val_loss: 1.5839 - val_accuracy: 0.6389\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.7349 - accuracy: 0.6338 - val_loss: 1.5688 - val_accuracy: 0.6111\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7081 - accuracy: 0.6268 - val_loss: 1.5315 - val_accuracy: 0.6389\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7088 - accuracy: 0.6408 - val_loss: 1.5421 - val_accuracy: 0.6111\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.7122 - accuracy: 0.6268 - val_loss: 1.5517 - val_accuracy: 0.6389\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7024 - accuracy: 0.6408 - val_loss: 1.5602 - val_accuracy: 0.6389\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6663 - accuracy: 0.6197 - val_loss: 1.5623 - val_accuracy: 0.6111\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6871 - accuracy: 0.6338 - val_loss: 1.5884 - val_accuracy: 0.6389\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6774 - accuracy: 0.6479 - val_loss: 1.6069 - val_accuracy: 0.6389\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6697 - accuracy: 0.6338 - val_loss: 1.5807 - val_accuracy: 0.6389\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6723 - accuracy: 0.6338 - val_loss: 1.5973 - val_accuracy: 0.6389\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6623 - accuracy: 0.6338 - val_loss: 1.6077 - val_accuracy: 0.6667\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6458 - accuracy: 0.6620 - val_loss: 1.5936 - val_accuracy: 0.6389\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6453 - accuracy: 0.6690 - val_loss: 1.5151 - val_accuracy: 0.6389\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.6293 - accuracy: 0.6549 - val_loss: 1.5280 - val_accuracy: 0.6389\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6301 - accuracy: 0.6620 - val_loss: 1.5920 - val_accuracy: 0.6389\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6344 - accuracy: 0.6549 - val_loss: 1.5886 - val_accuracy: 0.6389\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6115 - accuracy: 0.6761 - val_loss: 1.5520 - val_accuracy: 0.6111\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6121 - accuracy: 0.6549 - val_loss: 1.5321 - val_accuracy: 0.6389\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6223 - accuracy: 0.6620 - val_loss: 1.5266 - val_accuracy: 0.6389\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6072 - accuracy: 0.6690 - val_loss: 1.5150 - val_accuracy: 0.6111\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6033 - accuracy: 0.6479 - val_loss: 1.5433 - val_accuracy: 0.6111\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5967 - accuracy: 0.6479 - val_loss: 1.5416 - val_accuracy: 0.6389\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.5916 - accuracy: 0.6620 - val_loss: 1.5210 - val_accuracy: 0.6389\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6014 - accuracy: 0.6690 - val_loss: 1.5235 - val_accuracy: 0.6389\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6158 - accuracy: 0.6268 - val_loss: 1.5059 - val_accuracy: 0.6111\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6038 - accuracy: 0.6620 - val_loss: 1.5067 - val_accuracy: 0.6389\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5846 - accuracy: 0.6620 - val_loss: 1.5374 - val_accuracy: 0.6111\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5776 - accuracy: 0.6408 - val_loss: 1.5382 - val_accuracy: 0.6389\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5716 - accuracy: 0.6549 - val_loss: 1.5304 - val_accuracy: 0.6389\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5527 - accuracy: 0.6549 - val_loss: 1.4763 - val_accuracy: 0.6111\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5753 - accuracy: 0.6268 - val_loss: 1.4657 - val_accuracy: 0.6389\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5816 - accuracy: 0.6549 - val_loss: 1.4862 - val_accuracy: 0.6667\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.5367 - accuracy: 0.6549 - val_loss: 1.5149 - val_accuracy: 0.6111\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5721 - accuracy: 0.6056 - val_loss: 1.5278 - val_accuracy: 0.6111\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5341 - accuracy: 0.6549 - val_loss: 1.5587 - val_accuracy: 0.6389\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5635 - accuracy: 0.6761 - val_loss: 1.5134 - val_accuracy: 0.6389\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5421 - accuracy: 0.6408 - val_loss: 1.5523 - val_accuracy: 0.6389\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5391 - accuracy: 0.6479 - val_loss: 1.4622 - val_accuracy: 0.6389\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5254 - accuracy: 0.6831 - val_loss: 1.4795 - val_accuracy: 0.6389\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4912 - accuracy: 0.6690 - val_loss: 1.4861 - val_accuracy: 0.6111\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5198 - accuracy: 0.6620 - val_loss: 1.4361 - val_accuracy: 0.6111\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.5079 - accuracy: 0.6268 - val_loss: 1.4651 - val_accuracy: 0.6111\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5480 - accuracy: 0.6620 - val_loss: 1.4711 - val_accuracy: 0.6667\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5070 - accuracy: 0.6408 - val_loss: 1.5330 - val_accuracy: 0.6389\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4687 - accuracy: 0.6408 - val_loss: 1.4562 - val_accuracy: 0.6389\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5032 - accuracy: 0.6690 - val_loss: 1.4320 - val_accuracy: 0.6667\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4657 - accuracy: 0.6761 - val_loss: 1.4349 - val_accuracy: 0.6111\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4786 - accuracy: 0.6408 - val_loss: 1.4054 - val_accuracy: 0.6667\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4588 - accuracy: 0.6620 - val_loss: 1.3945 - val_accuracy: 0.6667\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4506 - accuracy: 0.6761 - val_loss: 1.4284 - val_accuracy: 0.6389\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4528 - accuracy: 0.6197 - val_loss: 1.4890 - val_accuracy: 0.6389\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4435 - accuracy: 0.6690 - val_loss: 1.4387 - val_accuracy: 0.6389\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4955 - accuracy: 0.6901 - val_loss: 1.4106 - val_accuracy: 0.6389\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4164 - accuracy: 0.6901 - val_loss: 1.4273 - val_accuracy: 0.6111\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4621 - accuracy: 0.6197 - val_loss: 1.3945 - val_accuracy: 0.6111\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4777 - accuracy: 0.6690 - val_loss: 1.3915 - val_accuracy: 0.6667\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4174 - accuracy: 0.6690 - val_loss: 1.4426 - val_accuracy: 0.6389\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4466 - accuracy: 0.6197 - val_loss: 1.4397 - val_accuracy: 0.6667\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4621 - accuracy: 0.6690 - val_loss: 1.4194 - val_accuracy: 0.6389\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4661 - accuracy: 0.6901 - val_loss: 1.5945 - val_accuracy: 0.6389\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4330 - accuracy: 0.6620 - val_loss: 1.4470 - val_accuracy: 0.6389\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4068 - accuracy: 0.6972 - val_loss: 1.3772 - val_accuracy: 0.6389\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4028 - accuracy: 0.6479 - val_loss: 1.3690 - val_accuracy: 0.6111\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4010 - accuracy: 0.6338 - val_loss: 1.3519 - val_accuracy: 0.6667\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3845 - accuracy: 0.6831 - val_loss: 1.3665 - val_accuracy: 0.6389\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3752 - accuracy: 0.6479 - val_loss: 1.4127 - val_accuracy: 0.6667\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3979 - accuracy: 0.6761 - val_loss: 1.4193 - val_accuracy: 0.6389\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3882 - accuracy: 0.6831 - val_loss: 1.4223 - val_accuracy: 0.6667\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3729 - accuracy: 0.6620 - val_loss: 1.3815 - val_accuracy: 0.6389\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3770 - accuracy: 0.6408 - val_loss: 1.3293 - val_accuracy: 0.6389\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.4065 - accuracy: 0.6972 - val_loss: 1.3136 - val_accuracy: 0.6667\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3676 - accuracy: 0.6761 - val_loss: 1.3694 - val_accuracy: 0.6667\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3908 - accuracy: 0.6338 - val_loss: 1.3335 - val_accuracy: 0.6389\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4070 - accuracy: 0.6901 - val_loss: 1.3239 - val_accuracy: 0.6667\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3450 - accuracy: 0.6901 - val_loss: 1.3383 - val_accuracy: 0.6389\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3977 - accuracy: 0.6338 - val_loss: 1.3577 - val_accuracy: 0.6667\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3521 - accuracy: 0.6761 - val_loss: 1.4199 - val_accuracy: 0.6944\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3610 - accuracy: 0.6831 - val_loss: 1.3702 - val_accuracy: 0.6667\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3358 - accuracy: 0.6690 - val_loss: 1.3461 - val_accuracy: 0.6389\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.3369 - accuracy: 0.6901 - val_loss: 1.3111 - val_accuracy: 0.6389\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3357 - accuracy: 0.6831 - val_loss: 1.2839 - val_accuracy: 0.6389\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3589 - accuracy: 0.6972 - val_loss: 1.2566 - val_accuracy: 0.6667\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4189 - accuracy: 0.6338 - val_loss: 1.3512 - val_accuracy: 0.6389\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2940 - accuracy: 0.6620 - val_loss: 1.3479 - val_accuracy: 0.6944\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4149 - accuracy: 0.7113 - val_loss: 1.3424 - val_accuracy: 0.6389\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3795 - accuracy: 0.6408 - val_loss: 1.4690 - val_accuracy: 0.6667\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3477 - accuracy: 0.6549 - val_loss: 1.3032 - val_accuracy: 0.6667\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3396 - accuracy: 0.7183 - val_loss: 1.2933 - val_accuracy: 0.6667\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3033 - accuracy: 0.6831 - val_loss: 1.3215 - val_accuracy: 0.6389\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2821 - accuracy: 0.6690 - val_loss: 1.2673 - val_accuracy: 0.6944\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.3241 - accuracy: 0.6972 - val_loss: 1.2608 - val_accuracy: 0.6389\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.2862 - accuracy: 0.6620 - val_loss: 1.2872 - val_accuracy: 0.6667\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2766 - accuracy: 0.6620 - val_loss: 1.2585 - val_accuracy: 0.6944\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3030 - accuracy: 0.7113 - val_loss: 1.2692 - val_accuracy: 0.6389\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3120 - accuracy: 0.6690 - val_loss: 1.2896 - val_accuracy: 0.6667\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2531 - accuracy: 0.7042 - val_loss: 1.2450 - val_accuracy: 0.6944\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2716 - accuracy: 0.7113 - val_loss: 1.2322 - val_accuracy: 0.6389\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2772 - accuracy: 0.6690 - val_loss: 1.2242 - val_accuracy: 0.6389\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.2563 - accuracy: 0.7042 - val_loss: 1.2453 - val_accuracy: 0.6667\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2660 - accuracy: 0.7042 - val_loss: 1.2385 - val_accuracy: 0.6389\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2894 - accuracy: 0.6338 - val_loss: 1.2614 - val_accuracy: 0.6667\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2296 - accuracy: 0.7042 - val_loss: 1.2662 - val_accuracy: 0.6667\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2933 - accuracy: 0.7183 - val_loss: 1.2162 - val_accuracy: 0.6389\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2472 - accuracy: 0.6690 - val_loss: 1.1768 - val_accuracy: 0.6667\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3214 - accuracy: 0.7324 - val_loss: 1.1950 - val_accuracy: 0.6944\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2410 - accuracy: 0.6761 - val_loss: 1.3271 - val_accuracy: 0.6389\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2453 - accuracy: 0.6761 - val_loss: 1.2509 - val_accuracy: 0.6667\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2435 - accuracy: 0.7254 - val_loss: 1.2406 - val_accuracy: 0.6667\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2198 - accuracy: 0.6972 - val_loss: 1.2273 - val_accuracy: 0.6667\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2113 - accuracy: 0.6972 - val_loss: 1.1907 - val_accuracy: 0.6944\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2171 - accuracy: 0.7183 - val_loss: 1.1707 - val_accuracy: 0.6667\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2129 - accuracy: 0.6831 - val_loss: 1.1448 - val_accuracy: 0.6667\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2310 - accuracy: 0.7042 - val_loss: 1.1330 - val_accuracy: 0.6944\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2359 - accuracy: 0.6831 - val_loss: 1.1873 - val_accuracy: 0.6389\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1929 - accuracy: 0.7113 - val_loss: 1.1972 - val_accuracy: 0.6944\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2223 - accuracy: 0.6761 - val_loss: 1.2831 - val_accuracy: 0.6667\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2002 - accuracy: 0.6901 - val_loss: 1.2822 - val_accuracy: 0.6944\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2075 - accuracy: 0.7113 - val_loss: 1.2704 - val_accuracy: 0.6944\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1986 - accuracy: 0.6972 - val_loss: 1.2138 - val_accuracy: 0.6667\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1770 - accuracy: 0.7183 - val_loss: 1.1046 - val_accuracy: 0.6944\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1817 - accuracy: 0.7183 - val_loss: 1.1047 - val_accuracy: 0.6944\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1915 - accuracy: 0.7183 - val_loss: 1.1175 - val_accuracy: 0.6667\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2147 - accuracy: 0.6761 - val_loss: 1.2363 - val_accuracy: 0.6944\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2022 - accuracy: 0.7394 - val_loss: 1.2225 - val_accuracy: 0.6944\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1691 - accuracy: 0.7254 - val_loss: 1.1431 - val_accuracy: 0.6389\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1741 - accuracy: 0.7113 - val_loss: 1.0949 - val_accuracy: 0.6944\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1536 - accuracy: 0.7113 - val_loss: 1.1291 - val_accuracy: 0.6667\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1614 - accuracy: 0.7254 - val_loss: 1.1580 - val_accuracy: 0.6667\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1383 - accuracy: 0.7324 - val_loss: 1.2081 - val_accuracy: 0.6667\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1797 - accuracy: 0.7042 - val_loss: 1.1118 - val_accuracy: 0.6667\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1634 - accuracy: 0.6972 - val_loss: 1.1530 - val_accuracy: 0.6944\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1453 - accuracy: 0.7535 - val_loss: 1.1212 - val_accuracy: 0.6944\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1421 - accuracy: 0.7394 - val_loss: 1.1485 - val_accuracy: 0.6667\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1378 - accuracy: 0.6901 - val_loss: 1.1182 - val_accuracy: 0.6389\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1278 - accuracy: 0.7324 - val_loss: 1.1209 - val_accuracy: 0.6944\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1271 - accuracy: 0.7535 - val_loss: 1.1878 - val_accuracy: 0.6667\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1769 - accuracy: 0.6620 - val_loss: 1.2611 - val_accuracy: 0.6667\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1334 - accuracy: 0.7042 - val_loss: 1.1381 - val_accuracy: 0.6944\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1198 - accuracy: 0.7465 - val_loss: 1.0884 - val_accuracy: 0.6944\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1176 - accuracy: 0.7113 - val_loss: 1.0686 - val_accuracy: 0.6667\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1044 - accuracy: 0.7254 - val_loss: 1.1056 - val_accuracy: 0.6667\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1203 - accuracy: 0.7535 - val_loss: 1.1181 - val_accuracy: 0.6944\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1436 - accuracy: 0.7042 - val_loss: 1.2103 - val_accuracy: 0.6944\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0978 - accuracy: 0.7183 - val_loss: 1.1280 - val_accuracy: 0.6944\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1103 - accuracy: 0.7394 - val_loss: 1.0748 - val_accuracy: 0.6667\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1498 - accuracy: 0.6831 - val_loss: 1.0983 - val_accuracy: 0.6944\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1365 - accuracy: 0.7183 - val_loss: 1.0590 - val_accuracy: 0.7222\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0913 - accuracy: 0.7254 - val_loss: 1.1426 - val_accuracy: 0.6667\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1244 - accuracy: 0.7113 - val_loss: 1.1568 - val_accuracy: 0.6944\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0993 - accuracy: 0.7183 - val_loss: 1.1416 - val_accuracy: 0.6944\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0820 - accuracy: 0.7254 - val_loss: 1.0845 - val_accuracy: 0.6944\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0608 - accuracy: 0.7113 - val_loss: 1.0778 - val_accuracy: 0.6944\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0601 - accuracy: 0.7394 - val_loss: 1.0467 - val_accuracy: 0.6944\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0761 - accuracy: 0.7535 - val_loss: 1.0291 - val_accuracy: 0.6667\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0873 - accuracy: 0.6901 - val_loss: 1.1243 - val_accuracy: 0.6944\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0444 - accuracy: 0.7394 - val_loss: 1.0660 - val_accuracy: 0.6944\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0964 - accuracy: 0.7465 - val_loss: 1.0930 - val_accuracy: 0.6944\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0379 - accuracy: 0.7324 - val_loss: 0.9747 - val_accuracy: 0.6944\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0930 - accuracy: 0.7535 - val_loss: 0.9749 - val_accuracy: 0.7222\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0792 - accuracy: 0.7324 - val_loss: 0.9679 - val_accuracy: 0.6944\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0430 - accuracy: 0.7465 - val_loss: 1.1013 - val_accuracy: 0.6944\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0787 - accuracy: 0.7394 - val_loss: 1.1824 - val_accuracy: 0.6944\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0470 - accuracy: 0.7324 - val_loss: 1.0146 - val_accuracy: 0.6667\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0732 - accuracy: 0.7676 - val_loss: 0.9571 - val_accuracy: 0.7222\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0566 - accuracy: 0.7183 - val_loss: 0.9726 - val_accuracy: 0.6944\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0074 - accuracy: 0.7465 - val_loss: 1.0330 - val_accuracy: 0.6944\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0509 - accuracy: 0.7676 - val_loss: 1.1368 - val_accuracy: 0.6944\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0547 - accuracy: 0.7676 - val_loss: 1.0241 - val_accuracy: 0.6944\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0194 - accuracy: 0.7324 - val_loss: 1.0266 - val_accuracy: 0.6944\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0139 - accuracy: 0.7394 - val_loss: 1.0375 - val_accuracy: 0.6944\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0166 - accuracy: 0.7535 - val_loss: 1.0318 - val_accuracy: 0.6944\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0231 - accuracy: 0.7535 - val_loss: 0.9881 - val_accuracy: 0.6667\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0456 - accuracy: 0.7254 - val_loss: 1.1452 - val_accuracy: 0.6944\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0224 - accuracy: 0.7394 - val_loss: 1.0535 - val_accuracy: 0.6944\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0295 - accuracy: 0.7676 - val_loss: 0.9991 - val_accuracy: 0.6944\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9969 - accuracy: 0.7394 - val_loss: 0.9425 - val_accuracy: 0.6944\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9865 - accuracy: 0.7746 - val_loss: 0.9386 - val_accuracy: 0.7222\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9912 - accuracy: 0.7887 - val_loss: 0.9740 - val_accuracy: 0.6944\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9941 - accuracy: 0.7183 - val_loss: 1.0243 - val_accuracy: 0.6944\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0162 - accuracy: 0.7817 - val_loss: 1.0370 - val_accuracy: 0.6944\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9838 - accuracy: 0.7394 - val_loss: 1.0640 - val_accuracy: 0.7222\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9948 - accuracy: 0.7183 - val_loss: 0.9399 - val_accuracy: 0.6944\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0145 - accuracy: 0.7817 - val_loss: 0.9467 - val_accuracy: 0.6944\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9652 - accuracy: 0.7535 - val_loss: 0.9809 - val_accuracy: 0.6944\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9588 - accuracy: 0.7535 - val_loss: 0.9304 - val_accuracy: 0.6944\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9781 - accuracy: 0.7817 - val_loss: 0.9323 - val_accuracy: 0.6944\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0627 - accuracy: 0.6901 - val_loss: 1.0799 - val_accuracy: 0.7222\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9661 - accuracy: 0.7817 - val_loss: 0.9696 - val_accuracy: 0.6944\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9536 - accuracy: 0.7817 - val_loss: 1.0380 - val_accuracy: 0.7222\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0057 - accuracy: 0.7042 - val_loss: 0.9648 - val_accuracy: 0.6944\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9700 - accuracy: 0.7746 - val_loss: 0.9456 - val_accuracy: 0.6667\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9427 - accuracy: 0.7887 - val_loss: 0.9296 - val_accuracy: 0.7500\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9524 - accuracy: 0.7394 - val_loss: 0.9034 - val_accuracy: 0.6667\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9580 - accuracy: 0.8099 - val_loss: 0.9081 - val_accuracy: 0.6944\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9444 - accuracy: 0.7535 - val_loss: 0.9835 - val_accuracy: 0.7500\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9432 - accuracy: 0.7465 - val_loss: 0.9114 - val_accuracy: 0.6944\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9345 - accuracy: 0.7746 - val_loss: 0.9765 - val_accuracy: 0.6944\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9263 - accuracy: 0.7887 - val_loss: 0.9635 - val_accuracy: 0.6944\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=300,validation_data=(X_test,y_test),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (FullyConnected) multiple                  896       \n",
      "_________________________________________________________________\n",
      "fully_connected (FullyConnec multiple                  2080      \n",
      "_________________________________________________________________\n",
      "fully_connected_1 (FullyConn multiple                  1056      \n",
      "_________________________________________________________________\n",
      "output_layer (FullyConnected multiple                  99        \n",
      "=================================================================\n",
      "Total params: 4,131\n",
      "Trainable params: 4,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "f,ax = plt.subplots(1,2,figsize=(15,6))\n",
    "\n",
    "ax[0].plot(history.history['val_loss'],label='Validation Loss')\n",
    "ax[0].plot(history.history['loss'],label='Training Loss')\n",
    "ax[0].set_title('Losses',weight='bold',size='x-large')\n",
    "ax[0].set_xlabel('Epoch',size='large')\n",
    "ax[0].set_ylabel('Loss',size='large')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(history.history['val_accuracy'],label='Validation Accuracy')\n",
    "ax[1].plot(history.history['accuracy'],label='Training Accuracy')\n",
    "ax[1].set_title('Accuracies',weight='bold',size='x-large')\n",
    "ax[1].set_xlabel('Epoch',size='large')\n",
    "ax[1].set_ylabel('Accuracy',size='large')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# End Notes\n",
    "There is a lot more that the `tf 2.0` offers you while building custom layers and models including **metrics**, **losses** and much more inside the layers. Please refer more at the official documentation. Hope you enjoyed reading. Good Luck with your journey."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
